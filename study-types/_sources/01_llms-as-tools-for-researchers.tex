\documentclass[11pt]{article}
\usepackage[parfill]{parskip} % use newlines for paragraphs (more similar to Markdown)

\begin{document}

\subsection{LLMs as Tools for Software Engineering Researchers}

LLMs can be leveraged as powerful tools to assist researchers conducting empirical studies.
They can automate various tasks such as data collection, preprocessing, and analysis.
For example, LLMs can apply pre-defined coding guides to large qualitative datasets (\textbf{annotation}), assess the quality of software artifacts (\textbf{rating}), generate summaries of research papers (\textbf{synthesis}), and even simulate human behavior in empirical studies (\textbf{subject}).
This can significantly reduce the time and effort required by researchers, allowing them to focus on more complex aspects of their studies.
However, all these applications also come with limitations, potential threats to validity, and implications for the reproducibility of study results.
In our guidelines, the following study types and used to contextualize the recommendations we provide.


\subsubsection{LLMs as Annotators}

\emph{Description:} LLMs can serve as annotators by automatically labeling artifacts with corresponding categories for data analysis based on a pre-defined coding guide.
In qualitative data analysis, manually annotating or coding text passages, e.g. in software artifacts, open-ended survey responses, or interview transcripts, is often a time-consuming manual process.
LLMs can be used to augment or even replace human annotations, provide suggestions for new codes (see \textbf{synthesis}), or even automate the entire process.

\emph{Example:} For example, in a study analyzing code changes in version control systems, researchers may need to categorize each individual change into predefined categories.
For that, they may use LLMs to analyze commit messages and categorize them using labels such as bug fixes, feature additions, or refactorings, based on a short description of each label.

\emph{Promises:} This automation can improve the efficiency of the annotation process, which is often a labor-intensive and error-prone task when done manually.

\emph{Perils:} In such tasks, LLMs have the potential to improve the accuracy and efficiency of automated labeling processes~\cite{DBLP:conf/kdd/WanSJKCNSSWYABJ24}, making them valuable tools for empirical research in software engineering.
Hybrid human-LLM annotation approaches may further increase accuracy and allow for the correction of incorrectly applied labels~\cite{DBLP:conf/chi/Wang0RMM24}.

\emph{Previous Work in SE:}  \textbf{TODO:} Examples of such studies in software engineering include...


\subsubsection{LLMs as Raters}

\emph{Description:} In empirical studies, LLMs can act as raters to evaluate the quality or other properties of software artifacts such as code, documentation, and design patterns.

\emph{Example:}  For instance, LLMs can be trained to assess code readability, adherence to coding standards, or the quality of comments. 

\emph{Promises:} By providing---depending on the model configuration---consistent and relatively ``objective'' evaluations, LLMs can help mitigate certain biases and part of the variability that human raters might introduce. 
This can lead to more reliable and reproducible results in empirical studies.

\emph{Perils:} However, when relying on the judgment of LLMs, researchers have to make sure to build a reliable process for generating ratings that considers the non-deterministic nature of LLMs and report the intricacies of that process transparently.

\emph{Previous Work in SE:}  \textbf{TODO:} Examples of such studies in software engineering include...


\subsubsection{LLMs for Synthesis}

\emph{Description:} LLMs can be used to synthesis large amounts of qualitative data.

\emph{Example:}  For example, they can summarize or compare papers for literature reviews or support researchers in deriving codes and developing coding guides during the initial phase of qualitative data analysis. Those code can then later be used to annotate more data (see \textbf{annotation}).

\emph{Promises:} \textbf{TODO}

\emph{Perils:} \textbf{TODO}

\emph{Previous Work in SE:}  \textbf{TODO:}  \textbf{TODO:} Examples of such studies in software engineering include...


\subsubsection{LLMs as Subjects}

\emph{Description:} LLMs can be used as subjects in empirical studies to simulate human behavior and interactions.

\emph{Example:} For example, researchers can use LLMs to generate responses in user studies, simulate developer interactions in collaborative coding environments, or model user feedback in software usability studies.

\emph{Promises:}  This approach can provide valuable insights while reducing the need to recruit human participants, which can be time-consuming and costly. Additionally, using LLMs as subjects allows for controlled experiments with consistent and repeatable conditions.

\emph{Perils:} However, it is important that researchers are aware of LLMs' inherent biases~\cite{Crowell2023} and limitations~\cite{DBLP:journals/ais/HardingDLL24} when using them as study subjects.

\emph{Previous Work in SE:}  \textbf{TODO:}  \textbf{TODO:} Examples of such studies in software engineering include...

\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
