@inproceedings{DBLP:conf/kdd/WanSJKCNSSWYABJ24,
  author       = {Mengting Wan and
                  Tara Safavi and
                  Sujay Kumar Jauhar and
                  Yujin Kim and
                  Scott Counts and
                  Jennifer Neville and
                  Siddharth Suri and
                  Chirag Shah and
                  Ryen W. White and
                  Longqi Yang and
                  Reid Andersen and
                  Georg Buscher and
                  Dhruv Joshi and
                  Nagu Rangan},
  editor       = {Ricardo Baeza{-}Yates and
                  Francesco Bonchi},
  title        = {TnT-LLM: Text Mining at Scale with Large Language Models},
  booktitle    = {Proceedings of the 30th {ACM} {SIGKDD} Conference on Knowledge Discovery
                  and Data Mining, {KDD} 2024, Barcelona, Spain, August 25-29, 2024},
  pages        = {5836--5847},
  publisher    = {{ACM}},
  year         = {2024},
  url          = {https://doi.org/10.1145/3637528.3671647},
  doi          = {10.1145/3637528.3671647},
  timestamp    = {Sun, 08 Sep 2024 16:05:57 +0200},
  biburl       = {https://dblp.org/rec/conf/kdd/WanSJKCNSSWYABJ24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/chi/Wang0RMM24,
  author       = {Xinru Wang and
                  Hannah Kim and
                  Sajjadur Rahman and
                  Kushan Mitra and
                  Zhengjie Miao},
  editor       = {Florian 'Floyd' Mueller and
                  Penny Kyburz and
                  Julie R. Williamson and
                  Corina Sas and
                  Max L. Wilson and
                  Phoebe O. Toups Dugas and
                  Irina Shklovski},
  title        = {Human-LLM Collaborative Annotation Through Effective Verification
                  of {LLM} Labels},
  booktitle    = {Proceedings of the {CHI} Conference on Human Factors in Computing
                  Systems, {CHI} 2024, Honolulu, HI, USA, May 11-16, 2024},
  pages        = {303:1--303:21},
  publisher    = {{ACM}},
  year         = {2024},
  url          = {https://doi.org/10.1145/3613904.3641960},
  doi          = {10.1145/3613904.3641960},
  timestamp    = {Fri, 17 May 2024 21:42:31 +0200},
  biburl       = {https://dblp.org/rec/conf/chi/Wang0RMM24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Crowell2023,
    author = {Rachel Crowell},
    title = {{Why AIâ€™s diversity crisis matters, and how to tackle it}},
    journal = {Nature Career Feature},
    year = {2023},
    doi = {10.1038/d41586-023-01689-4},
    url = {https://doi.org/10.1038/d41586-023-01689-4}
}

@article{DBLP:journals/ais/HardingDLL24,
  author       = {Jacqueline Harding and
                  William D'Alessandro and
                  N. G. Laskowski and
                  Robert Long},
  title        = {{AI} language models cannot replace human research participants},
  journal      = {{AI} Soc.},
  volume       = {39},
  number       = {5},
  pages        = {2603--2605},
  year         = {2024},
  url          = {https://doi.org/10.1007/s00146-023-01725-x},
  doi          = {10.1007/S00146-023-01725-X},
  timestamp    = {Tue, 22 Oct 2024 21:07:56 +0200},
  biburl       = {https://dblp.org/rec/journals/ais/HardingDLL24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/pacmse/KhojahM0N24,
  author       = {Ranim Khojah and
                  Mazen Mohamad and
                  Philipp Leitner and
                  Francisco Gomes de Oliveira Neto},
  title        = {Beyond Code Generation: An Observational Study of ChatGPT Usage in
                  Software Engineering Practice},
  journal      = {Proc. {ACM} Softw. Eng.},
  volume       = {1},
  number       = {{FSE}},
  pages        = {1819--1840},
  year         = {2024},
  url          = {https://doi.org/10.1145/3660788},
  doi          = {10.1145/3660788},
  timestamp    = {Fri, 02 Aug 2024 21:41:22 +0200},
  biburl       = {https://dblp.org/rec/journals/pacmse/KhojahM0N24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icse/ChoudhuriLSGS24,
  author       = {Rudrajit Choudhuri and
                  Dylan Liu and
                  Igor Steinmacher and
                  Marco Aur{\'{e}}lio Gerosa and
                  Anita Sarma},
  title        = {How Far Are We? The Triumphs and Trials of Generative {AI} in Learning
                  Software Engineering},
  booktitle    = {Proceedings of the 46th {IEEE/ACM} International Conference on Software
                  Engineering, {ICSE} 2024, Lisbon, Portugal, April 14-20, 2024},
  pages        = {184:1--184:13},
  publisher    = {{ACM}},
  year         = {2024},
  url          = {https://doi.org/10.1145/3597503.3639201},
  doi          = {10.1145/3597503.3639201},
  timestamp    = {Mon, 09 Dec 2024 22:46:00 +0100},
  biburl       = {https://dblp.org/rec/conf/icse/ChoudhuriLSGS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1145/3695988,
author = {Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu},
title = {Large Language Models for Software Engineering: A Systematic Literature Review},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695988},
doi = {10.1145/3695988},
abstract = {Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a Systematic Literature Review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We selected and analyzed 395 research articles from January 2017 to January 2024 to answer four key Research Questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, pre-processing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and highlighting promising areas for future study. Our artifacts are publicly available at .},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {220},
numpages = {79},
keywords = {Software Engineering, Large Language Model, Survey}
}

@article{DBLP:journals/corr/abs-2107-03374,
  author       = {Mark Chen and
                  Jerry Tworek and
                  Heewoo Jun and
                  Qiming Yuan and
                  Henrique Pond{\'{e}} de Oliveira Pinto and
                  Jared Kaplan and
                  Harri Edwards and
                  Yuri Burda and
                  Nicholas Joseph and
                  Greg Brockman and
                  Alex Ray and
                  Raul Puri and
                  Gretchen Krueger and
                  Michael Petrov and
                  Heidy Khlaaf and
                  Girish Sastry and
                  Pamela Mishkin and
                  Brooke Chan and
                  Scott Gray and
                  Nick Ryder and
                  Mikhail Pavlov and
                  Alethea Power and
                  Lukasz Kaiser and
                  Mohammad Bavarian and
                  Clemens Winter and
                  Philippe Tillet and
                  Felipe Petroski Such and
                  Dave Cummings and
                  Matthias Plappert and
                  Fotios Chantzis and
                  Elizabeth Barnes and
                  Ariel Herbert{-}Voss and
                  William Hebgen Guss and
                  Alex Nichol and
                  Alex Paino and
                  Nikolas Tezak and
                  Jie Tang and
                  Igor Babuschkin and
                  Suchir Balaji and
                  Shantanu Jain and
                  William Saunders and
                  Christopher Hesse and
                  Andrew N. Carr and
                  Jan Leike and
                  Joshua Achiam and
                  Vedant Misra and
                  Evan Morikawa and
                  Alec Radford and
                  Matthew Knight and
                  Miles Brundage and
                  Mira Murati and
                  Katie Mayer and
                  Peter Welinder and
                  Bob McGrew and
                  Dario Amodei and
                  Sam McCandlish and
                  Ilya Sutskever and
                  Wojciech Zaremba},
  title        = {Evaluating Large Language Models Trained on Code},
  journal      = {CoRR},
  volume       = {abs/2107.03374},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.03374},
  eprinttype    = {arXiv},
  eprint       = {2107.03374},
  timestamp    = {Tue, 20 Aug 2024 16:58:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2107-03374.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2410-16186,
  author       = {Sanchit Ahuja and
                  Varun Gumma and
                  Sunayana Sitaram},
  title        = {Contamination Report for Multilingual Benchmarks},
  journal      = {CoRR},
  volume       = {abs/2410.16186},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2410.16186},
  doi          = {10.48550/ARXIV.2410.16186},
  eprinttype    = {arXiv},
  eprint       = {2410.16186},
  timestamp    = {Tue, 26 Nov 2024 15:54:21 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2410-16186.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/acl/SiskaMAB24,
  author       = {Charlotte Siska and
                  Katerina Marazopoulou and
                  Melissa Ailem and
                  James Bono},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Examining the robustness of {LLM} evaluation to the distributional
                  assumptions of benchmarks},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {10406--10421},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.560},
  doi          = {10.18653/V1/2024.ACL-LONG.560},
  timestamp    = {Tue, 24 Sep 2024 10:55:47 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/SiskaMAB24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
