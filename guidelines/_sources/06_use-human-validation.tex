\input{../../header.tex}

\begin{document}

\subsection{Use Human Validation for LLM Outputs}

\subsubsection{Recommendations}

While LLMs can automate many tasks, it is important to validate their outputs with human judgment.
For natural language processing tasks, a large-scale study has shown that LLMs have significant variation in their results, which limits their reliability as a direct substitute for human raters~\cite{DBLP:journals/corr/abs-2406-18403}. 
Human validation helps ensure the accuracy and reliability of the results, as LLMs may sometimes produce incorrect or biased outputs.
Especially in studies where LLMs are used to support researchers, human validation is generally recommended to ensure validity.
For studies using LLMs as annotators, the proposed process by Ahmed et al.~\cite{DBLP:journals/corr/abs-2408-05534}, which includes an initial few-shot learning and, given good results, the replacement of \emph{one} human annotator by an LLM, might be a way forward.

Researchers may employ human validation to complement existing measures of software-related constructs.
For example, proxies for software quality, such as code complexity or the number of code smells, may be complemented by human ratings of maintainability, readability, or understandability.
In the case of more abstract variables or psychometric measurements, human validation may be the only way of measuring a specific construct.
For example, measuring human factors such as trust, cognitive load, and comprehension levels may inherently require human evaluation.

When conducting empirical measurements, researchers should clearly define the construct that they are measuring and specify the methods used for measurement.
Further, they should use established measurement methods and instruments that are empirically validated~\cite{DBLP:journals/fcomp/HoffmanMKL23, DBLP:conf/chi/PerrigSB23}.
Measuring a construct may require aggregating input from multiple subjects. 
For example, a study may assess inter-rater agreement using measures such as Cohen's Kappa or Krippendorff’s Alpha before aggregating ratings.
In some cases, researchers may also combine multiple measures into single composite measures.
As an example, they may evaluate both the time taken and accuracy when completing a task and aggregate them into a composite measure for the participants' overall performance.
In these cases, researchers should clearly describe their method of aggregation and document their reasoning for doing so.

When employing human validation, additional confounding factors should be controlled for, such as the level of expertise or experience with LLM-based applications or their general attitude towards AI-based tools.
Researchers should control for these factors through methods such as stratified sampling or by categorizing participants based on experience levels.

\subsubsection{Example(s)}

As an example, Khojah et al.~\cite{DBLP:journals/pacmse/KhojahM0N24} augmented the results of their study using human measurement.
Specifically, they asked participants to provide ratings regarding their experience, trust, perceived effectiveness and efficiency, and scenarios and lessons learned in their experience with ChatGPT.

Choudhuri et al.~\cite{DBLP:conf/icse/ChoudhuriLSGS24} evaluated the perceptions of students of their experience with ChatGPT in a controlled experiment.
They added this data to extend their results from the task performance in a series of software engineering tasks.

Xue et al.~\cite{DBLP:conf/icse/XueCBTH24} conducted a controlled experiment in which they evaluated the impact of ChatGPT on the performance and perceptions of students in an introductory programming course.
They employed multiple measures to judge the impact of the LLM from the perspective of humans.
In their study, they recorded the students' screens, evaluated the answers they provided in tasks, and distributed a post-study survey to get direct opinions from the students.

\comment{Maybe \cite{hymel2025analysisllmsvshuman} would also be an interesting paper to discuss?}

\subsubsection{Advantages}

Incorporating human judgment in the evaluation process adds a layer of quality control and increases the trustworthiness of the study’s findings, especially when explicitly reporting inter-rater reliability metrics. For instance, ``A subset of 20\% of the LLM-generated annotations was reviewed and validated by experienced software engineers to ensure accuracy. Using Cohen's Kappa, an inter-rater reliability of $\kappa = 0.90$ was reached.''

Incorporating feedback from individuals from the target population strengthens external validity by grounding study findings in real-world usage scenarios and may positively impact the transfer of study results to practice.
Researchers may uncover additional opportunities to further improve the LLM or LLM-based tool based on the reported experiences.

\subsubsection{Challenges}

Measuring variables through human validation can be challenging.
Ensuring that the operationalization of a desired construct and the method of measuring it are appropriate requires a good understanding of the studied concept and construct validity in general, and a systematic design approach for the measurement instruments.

Human judgment is often very subjective and may lead to large variability between different subjects due to differences in expertise, interpretation, and biases among evaluators.
Controlling for this subjectivity will require additional rigor when conducting the statistical analysis of the study results.

Recruiting participants as human validators will always incur additional resources compared to machine-generated measures.
Researchers must weigh the cost and time investment incurred by the recruitment process against the potential benefits for the validity of their study results.

\subsubsection{Study Types}

These guidelines apply to any study type that incorporates human validation.

\textbf{MUST}
\begin{itemize}
    \item Clearly define the construct measured through human validation.
    \item Describe how the construct is operationalized in the study, specifying the method of measurement.
    \item Employ established and widely accepted measurement methods and instruments.
\end{itemize}

\textbf{SHOULD}
\begin{itemize}
    \item Use empirically validated measures.
    \item Complement automated or machine-generated measures with human validation where possible.
\end{itemize}

\textbf{MAY}
\begin{itemize}
    \item Use multiple different measures (e.g., expert ratings, surveys, task performance) for human validation.
\end{itemize}

\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
