\documentclass[11pt]{article}
\usepackage[parfill]{parskip} % use newlines for paragraphs (more similar to Markdown)
\newcommand{\todo}[1]{{\textbf{TODO:}\ \textit{#1}}} % command for TODOs
\usepackage{hyperref}

\begin{document}

\subsection{Use Human Validation for LLM Outputs}

\subsubsection{Recommendations}

While LLMs can automate many tasks, it is important to validate their outputs with human annotations, at least partially. 
For natural language processing tasks, a large-scale study has shown that LLMs have too large a variation in their results to be reliably used as a substitution for human raters~\cite{DBLP:journals/corr/abs-2406-18403}. 
Human validation helps ensure the accuracy and reliability of the results, as LLMs may sometimes produce incorrect or biased outputs.
Especially in studies where LLMs are used to support researchers, human validation should always be employed.
For studies using LLMs as annotators, the proposed process by Ahmed et al.~\cite{DBLP:journals/corr/abs-2408-05534}, which includes an initial few-shot learning and, given good results, the replacement of \emph{one} human annotator by an LLM, might be a way forward.

Researchers may employ human validation to augment existing proxy measures.
For example, proxies for software quality, such as code complexity or the number of code smells may be augmented by human ratings of quality.
In the case of more abstract variables or psychometric measurements, human validation may be the only way of measuring a specific construct.
For example, measuring human factors, such as trust, cognitive load, and the level comprehension may implicitly require human measurement.

When conducting empirical measurements, researchers should clearly define the construct that they are measuring and the method of measurement they employ.
Further, they should use established measurement methods and instruments~\cite{DBLP:journals/fcomp/HoffmanMKL23} that are empirically validated~\cite{DBLP:conf/chi/PerrigSB23}.

When employing human validation, additional confounding factors should be controlled for, such as the level of expertise or experience with LLM-based applications and the general attitude towards AI-based tools.

\subsubsection{Example(s)}

\todo{write paragraph}
As an example, Khojah et al.~\cite{DBLP:journals/pacmse/KhojahM0N24} augmented the results of their study using human measurement.
Specifically, they asked participants to provide ratings regarding their experience, trust, perceived effectiveness and efficiency, and scenarios and lessons learned in their experience with ChatGPT.

Choudhuri et al.~\cite{DBLP:conf/icse/ChoudhuriLSGS24} evaluated the perceptions of students of their experience with ChatGPT in a controlled experiment.
They added this data to extend their results from the task performance of in a series of software engineering tasks.

Xue et al~\cite{DBLP:conf/icse/XueCBTH24} conducted a controlled experiment in which they evaluated the impact of ChatGPT on the performance and perceptions of students in an introductory programming course.
They employed multiple measures to judge the impact of the LLM through the perspective of humans.
In their study, they recorded the students' screens, evaluated the answers they provided in tasks, and distributed a post-study survey to get direct opinions from the students.


\subsubsection{Advantages}

Incorporating human judgment in the evaluation process adds a layer of quality control and increases the trustworthiness of the studyâ€™s findings, especially when explicitly reporting inter-rater reliability metrics. For instance, ``A subset of 20\% of the LLM-generated annotations were reviewed and validated by experienced software engineers to ensure accuracy. An inter-rater reliability of 90\% was reached.''

Adding human feedback from individuals from the target population may also help grounding the study results 

positively impact the practical application of the LLMs in the future.
Researchers may uncover additional opportunities to further improve the LLM or LLM-based tool based on these experiences.

\subsubsection{Challenges}

Measuring variables through human validation can be challenging.
Ensuring that the operationalization of a desired construct and the method of measuring it are appropriate requires a good understanding of the construct itself and a systematic design approach for the measurement instruments.

Human judgment is often very subjective and may lead to large variability between different subjects.
Controlling for this subjectivity will require additional rigor when conducting the statistical analysis of the study results.

Recruiting participants as human validators will always incur additional resources compared to machine-generated measures.
Researchers must balance the cost and time investment required for the recruitment process with the potential benefits for the validity of their study results.

\subsubsection{Study Types}

The guidelines apply to all study types if human validation is employed.

MUST
- Clearly define the construct measured by the human validation
- Clearly describe the method of measurement and operationalization of the measured construct
- Use established measurement methods and instruments

SHOULD
- Use empirically validated measures
- Augment automated or machine-generated measures with human validation where possible

MAY
- Use multiple different measures for human validation


\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
