\input{../../header.tex}

\begin{document}

\subsection{Report Model Version and Configuration}

\subsubsection{Recommendations}

LLMs (especially when used as a service) are frequently updated, and different versions may produce varying results.
Moreover, the model configuration and parameters influence the output generation of the models.
It is crucial to document the specific version of the LLM used in the study, along with the date when the experiments were conducted, and the exact configuration being used.
Furthermore, detailed documentation of the configuration and parameters used during the study is necessary for reproducibility. 
Depending on the specific study context, additional information regarding the architecture of the tool or experiment needs to be reported (see Section \href{/guidelines/#report-tool-architecture-and-supplemental-data}{Report Tool Architecture and Supplemental Data}).
Our recommendations is to report:

\begin{itemize}
\item Model name.
\item Model version (including a checksum if available).
\item The configured temperature that controls randomness, and all other relevant parameters that affect output generation (e.g., whether a seed value was configured).
\item The context window (number of tokens).
\item Whether historical context was considered when generating responses.
\end{itemize}

\subsubsection{Example(s)}

For an OpenAI model, researchers might report that "A  \texttt{gpt-4} model was integrated via the Azure OpenAI Service, and configured with a temperature of 0.7, top\_p set to 0.8, and a maximum token length of 512. We used version \texttt{0125-Preview}, system fingerprint \texttt{fp\_6b68a8204b}, seed value \texttt{23487}, and ran our experiment on 10th January 2025''~\cite{OpenAI25, Azure25}.
Similar statements can be made for self-hosted models, for which supplementary material can report specific instructions for reproducing results.
For example, for models provisioned using \href{https://ollama.com/library/}{ollama}, one can report the specific tag and checksum of the model being used, e.g., `llama3.3, tag 70b-instruct-q8\_0, checksum d5b5e1b84868`.
Given suitable hardware, running the corresponding model in its default configuration is then as easy as executing \texttt{ollama run llama3.3:70b-instruct-q8\_0} (see Section \href{/guidelines/#use-an-open-llm-as-a-baseline}{Use an Open LLM as a Baseline}).

Kang et al.~provide a similar statement in their paper on exploring LLM-based general bug reproduction~\cite{DBLP:conf/icse/KangYY23}:

\begin{quote}
\it
``We access OpenAI Codex via its closed beta API, using the code-davinci-002 model. For Codex, we set the temperature to 0.7, and the maximum number of tokens to 256.''
\end{quote}

Our guidelines additionally suggest to report a checksum and exact dates, but otherwise this example is close to our recommendations. 

\subsubsection{Advantages}

The recommended information is a prerequisite to enable reproducibility of LLM-based studies under the same or similar conditions.
% Mircea: The following lines no not read exactly as Advantages. 
% But I also don't know what to do with them :) They are valuable. 
% Could they be moved to Challenges? 
However, this information alone is generally not sufficient. 
Depending on the specific study setup, additional information about the architecture and data (\href{/guidelines/#report-tool-architecture-and-supplemental-data}{Report Tool Architecture and Supplemental Data}), prompts (\href{/guidelines/#report-prompts-and-their-development}{Report Prompts and their Development}), interaction logs (\href{/guidelines//#report-interaction-logs}{Report Interaction Logs}), and specific limitations an mitigations (\href{/guidelines/#report-limitations-and-mitigations}{Report Limitations and Mitigations}) need to be reported.

\subsubsection{Challenges}

Different model providers and modes of operating the models allow for varying degrees of information.
For example, OpenAI provides a model version and a system fingerprint describing the backend configuration that can also influence the output.
However, the fingerprint is indeed just intended to detect changes to the model or its configuration.
As a user, one cannot go back to a certain fingerprint.
As a beta feature, OpenAI also lets users set a seed parameter to receive ``(mostly) consistent output''~\cite{OpenAI23}.
However, the seed value does not allow for full reproducibility and the fingerprint changes frequently. 
While, as motived above, open models significantly simplify re-running experiments, they also come with challenges in terms of reproducibility, as generated outputs can be inconsistent despite setting the temperature to 0 and using a seed value (see \href{https://github.com/ollama/ollama/issues/5321}{GitHub issue for Llama3}).

\subsubsection{Study Types}

This guideline \must be followed for all study types for which the researcher has control over the model and its configuration. % Mircea: "control" or "access" to configuration? 
When \href{/study-types/#studying-llm-usage-in-software-engineering}{Studying LLM Usage in Software Engineering}, for example the usage of commercial tools such as ChatGPT or GitHub Copilot, researchers \must be as specific as possible in describing their studies.
The model name and date \must always be reported.
In those cases, reporting other aspects such as prompts (\href{/guidelines/#report-prompts-and-their-development}{Report Prompts and their Development}) and interaction logs (\href{/guidelines//#report-interaction-logs}{Report Interaction Logs}) is essential.
% I Like this discussion! I like the nuance of, if you can't ensure well enough the reproducibility, then at least make the effort to report interaction logs! 
% I wonder if this part could be consolidated together with the one above in Advantages that I was whether it fits well enough there. 

\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
