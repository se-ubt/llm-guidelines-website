\documentclass[11pt]{article}
\usepackage[parfill]{parskip} % use newlines for paragraphs (more similar to Markdown)
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{amsmath}

% custom commands:
\newcommand{\todo}[1]{{\textbf{TODO:}\ \textit{#1}}} % command for TODOs
\newcommand{\comment}[1]{{\textbf{Comment:}\ \textit{#1}}} % command for review comments

% RFC 2119 (https://www.rfc-editor.org/rfc/rfc2119)
% MUST: absolute requirement
\newcommand{\must}{\textbf{MUST}\xspace}
% MUST NOT: absolute prohibition
\newcommand{\mustnot}{\textbf{MUST NOT}\xspace}
% SHOULD: there may exist valid reasons in particular circumstances to ignore a  particular item, but the full implications must be understood and carefully weighed before choosing a different course
\newcommand{\should}{\textbf{SHOULD}\xspace}
% SHOULD NOT: there may exist valid reasons in particular circumstances when the particular behavior is acceptable or even useful, but the full implications should be understood and the case carefully weighed before implementing any behavior described with this label
\newcommand{\shouldnot}{\textbf{SHOULD NOT}\xspace}
% MAY: an item is truly optional
\newcommand{\may}{\textbf{MAY}\xspace}

\begin{document}

\subsection{Report Interaction Logs}

\subsubsection{Recommendations}

Given that commercial LLMs and LLM-based tools are evolving systems (minor upgrades of a major version are likely to be deployed frequently~\cite{DBLP:journals/corr/abs-2307-09009} and that they behave non-deterministically~\cite{Chann2023} even with a temperature of 0, reporting the prompts and model versions alone will not be enough to enable reproducibility.
Even for models such as Llama~\cite{Meta2025} that researchers can host and configure themselves, reaching complete determinism is challenging.
While decoding strategies and parameters can be fixed (e.g., by defining seeds, setting temperature to 0, using deterministic decoding strategies etc.), non-determinism can also arise from batching, input preprocessing, and floating point arithmetic on GPUs.
For complete transparency, researchers should report full interaction logs, that is all prompts and responses generated by the LLM or LLM-based tool, in the context of the presented study.
Reporting this is especially important when reporting a study targeting commercial SaaS solutions based on LLMs (e.g., ChatGPT) or novel tools that integrate LLMs via cloud APIs.


\subsubsection{Example(s)}

\todo{write paragraph}


\subsubsection{Advantages}

In this sense, the way an LLM has to be treated is similar to the way a human participant in an interview would be treated, because both the human and the LLM might provide different answers if presented with the same questions at different times.
The difference is that, while for human participants conversations often cannot be reported due to confidentiality, LLM conversations can.


\subsubsection{Challenges}

\todo{write paragraph}


\subsubsection{Study Types}

\todo{Connect guideline to study types and for each type have bullet point lists with information that MUST, SHOULD, or MAY be reported (usage of those terms according to RFC 2119~\cite{rfc2119}).}


\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
