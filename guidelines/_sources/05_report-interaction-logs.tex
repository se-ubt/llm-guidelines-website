\documentclass[11pt]{article}
\usepackage[parfill]{parskip} % use newlines for paragraphs (more similar to Markdown)
\newcommand{\todo}[1]{{\textbf{TODO:}\ \textit{#1}}} % command for TODOs
\usepackage{hyperref}

\begin{document}

\subsection{Report Interaction Logs}

\subsubsection{Recommendations}

Given that commercial LLMs and LLM-based tools are fast evolving systems, minor upgrades of a major version are likely to be deployed (for cloud-based versions) and released (for open-source versions) frequently~\cite{DBLP:journals/corr/abs-2307-09009}. 

This is why, if reproducibility is important, even reporting the whole version and parameters might not sufficient since these models can still behave non-deterministically~\cite{Chann2023}. Indeed, while decoding strategies and parameters can be fixed by defining seeds, setting temperature to 0, using deterministic decoding strategies etc., non-determinism can also arise from batching, input preprocessing, and floating point arithmetic on GPUs.

For complete transparency, researchers should when possible report full interaction logs, that is, all prompts and responses generated by the LLM or LLM-based tool in the context of the presented study. 
Reporting this is especially important when reporting a study targeting commercial SaaS solutions based on LLMs (e.g., ChatGPT) or novel tools that integrate LLMs via cloud APIs.

In a sense, this is not different than reporting results of interviews with human studies in qualitative studies that include interviews: there researchers also report the full interaction between the interviewers and the participants. Intuitively, this is defensible because both a human participant and the OpenAI ChatGPT might {\em changed their answers} if asked the same question at two months distance.



\subsubsection{Example(s)}

\todo{write paragraph}
- should try to find papers that do this... 


\subsubsection{Advantages}

The advantage of following this guideline is the transparency and reproducibility that a study that follows it will obtain. 

Moreover, the transcripts are easier to obtain from an interaction with an agent than actual interviews with users where the transcription used to be a time-consuming aspect. Even for systems where the interaction was with voice, the interaction is first translated to text, so it can also easily be obtained. In this sense, there is no excuse for researchers not reporting full transcripts. 

One other advantage is that, while for human participants conversations often cannot be reported due to confidentiality, LLM conversations can (e.g. as of beginning of 2025, the for-profile OpenAI company allows the sharing of chat transcripts: https://openai.com/policies/sharing-publication-policy/). 


\subsubsection{Challenges}

Given that {\em chat transcripts} are easy to generate, a study might end up with a very large appendix. Consequently, online storage might be recommended. Services such as Zenodo might be useful.

Some kinds of systems might be much harder to replicate. E.g. the fact that GitHub Copilot provided a recommendation during a coding session can not be replicated unless one re-creates the whole codebase state at that given point in time (and that of GitHub Copilot too). THis is unrealistic to expect to be reported. 


\subsubsection{Study Types}

\todo{Connect guideline to study types and for each type have bullet point lists with information that MUST, SHOULD, or MAY be reported (usage of those terms according to RFC 2119~\cite{rfc2119}).}


\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
