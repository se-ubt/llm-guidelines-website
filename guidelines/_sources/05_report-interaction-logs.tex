\documentclass[11pt]{article}
\usepackage[parfill]{parskip} % use newlines for paragraphs (more similar to Markdown)
\newcommand{\todo}[1]{{\textbf{TODO:}\ \textit{#1}}} % command for TODOs
\usepackage{hyperref}

\begin{document}

\subsection{Report Interaction Logs}

\subsubsection{Recommendations}

Given that commercial LLMs and LLM-based tools are fast evolving systems, minor upgrades of a major version are likely to be often deployed (for cloud-based versions) and released (for open-source versions) frequently~\cite{DBLP:journals/corr/abs-2307-09009}. Previous guidelines aim to address the reproducibility problem in this context, but even reporting full version and parameters might not be always sufficient. 

Indeed, LLMs can still behave non-deterministically even if parameters are fixed~\cite{Chann2023}: while decoding strategies and parameters can be fixed by defining seeds, setting temperature to 0, using deterministic decoding strategies etc., non-determinism can arise from batching, input preprocessing, and floating point arithmetic on GPUs. 

This is why, when reproducibility is important and transparency is needed, researchers should report full interaction logs, that is, all prompts and responses generated by the LLM or LLM-based tool in the context of the presented study. 
Reporting this is especially important when reporting a study targeting commercial SaaS solutions based on LLMs (e.g., ChatGPT) or novel tools that integrate LLMs via cloud APIs where there is even less guarantee of reproducing the state of the LLM-powered system at a later point by a reader of the study who wants to replicate it. 

In a sense, this is not different than reporting results of interviews with human studies in qualitative studies that include interviews: there researchers also report the full interaction between the interviewers and the participants. Intuitively, this is the same because both a human participant and the OpenAI ChatGPT might {\em change their answers} if asked the same question at two months distance; thus the transcript of the actual conversation is important to be tracked.


\subsubsection{Example(s)}

I could not find any paper that provided full transcripts. Does anybody have one? 


\subsubsection{Advantages}

The advantage of following this guideline is the transparency and reproducibility of the resulting research. 

Moreover, the guideline is easy to follow. Transcripts are easy to obtain (if we continue with the mental model of a LLM as an interviewee, this is especially evident in contrast with obtaining transripts with human users). Even for systems where the interaction is based on voice, the interaction is first translated to text using speech-to-text methods, so it can also be easily obtained. In this sense, there is no excuse for researchers not reporting full transcripts. 

One other advantage is that, while for human participants conversations often cannot be reported due to confidentiality, LLM conversations can (e.g. as of beginning of 2025, the for-profile OpenAI company allows the sharing of chat transcripts: https://openai.com/policies/sharing-publication-policy/). 


\subsubsection{Challenges}

Given that {\em chat transcripts} are easy to generate, a study might end up with a very large appendix. Consequently, online storage might be needed. Services such as Zenodo, or other long term storage for research work, will likely be used in such a situation.

Some kinds of systems might be much harder to report the interaction logs of than others. E.g. chat bot systems are easy to report the interactions with; OTOH, auto-complete systems, like GitHub Copilot, will be much harder to report. Indeed, the fact that CoPilot provided a recommendation during a coding session can not be replicated unless one re-creates the whole codebase state at that given point in time (and that of GitHub Copilot too). Expecting one to replicate this is unrealistic. At the same time, it sheds doubt on the replicability of such studies in general.  


\subsubsection{Study Types}

\todo{Connect guideline to study types and for each type have bullet point lists with information that MUST, SHOULD, or MAY be reported (usage of those terms according to RFC 2119~\cite{rfc2119}).}


\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
