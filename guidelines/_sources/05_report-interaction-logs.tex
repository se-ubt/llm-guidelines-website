\documentclass[11pt]{article}
\usepackage[parfill]{parskip} % use newlines for paragraphs (more similar to Markdown)
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{amsmath}

% custom commands:
\newcommand{\todo}[1]{{\textbf{TODO:}\ \textit{#1}}} % command for TODOs

% RFC 2119 (https://www.rfc-editor.org/rfc/rfc2119)
% MUST: absolute requirement
\newcommand{\must}{\textbf{MUST}\xspace}
% MUST NOT: absolute prohibition
\newcommand{\mustnot}{\textbf{MUST NOT}\xspace}
% SHOULD: there may exist valid reasons in particular circumstances to ignore a  particular item, but the full implications must be understood and carefully weighed before choosing a different course
\newcommand{\should}{\textbf{SHOULD}\xspace}
% SHOULD NOT: there may exist valid reasons in particular circumstances when the particular behavior is acceptable or even useful, but the full implications should be understood and the case carefully weighed before implementing any behavior described with this label
\newcommand{\shouldnot}{\textbf{SHOULD NOT}\xspace}
% MAY: an item is truly optional
\newcommand{\may}{\textbf{MAY}\xspace}

\begin{document}

\subsection{Report Interaction Logs}

\subsubsection{Recommendations}

Previous guidelines aim to address the reproducibility problem in this context, but even reporting full version and parameters might not be always sufficient. Indeed, LLMs can still behave non-deterministically even if parameters are fixed~\cite{Chann2023}: while decoding strategies and parameters can be fixed by defining seeds, setting temperature to 0, using deterministic decoding strategies etc., non-determinism can arise from batching, input preprocessing, and floating point arithmetic on GPUs. 

This is why, when reproducibility is important and transparency is needed, researchers should report full interaction logs, that is, all prompts and responses generated by the LLM or LLM-based tool in the context of the presented study. 
Reporting this is especially important when reporting a study targeting commercial SaaS solutions based on LLMs (e.g., ChatGPT) or novel tools that integrate LLMs via cloud APIs where there is even less guarantee of reproducing the state of the LLM-powered system at a later point by a reader of the study who wants to replicate it. 

In a sense, this is not different than reporting results of interviews with human studies in qualitative studies that include interviews: there researchers also report the full interaction between the interviewers and the participants. Intuitively, this is the same because both a human participant and the OpenAI ChatGPT might {\em change their answers} if asked the same question at two months distance; thus the transcript of the actual conversation is important to be tracked.


\subsubsection{Example(s)}

In their paper ``Investigating ChatGPT's Potential to Assist in Requirements Elicitation Processes'' \cite{ronanki2023investigating}, Ronanki et al. report the full answers of ChatGPT and they upload them in a Zenodo record \href{https://zenodo.org/records/8124936}. 

\TODO{QUESTION: Does anybody have a better example? I could not find one}. 


\subsubsection{Advantages}

The advantage of following this guideline is the transparency and reproducibility of the resulting research. 

Moreover, the guideline is easy to follow. Transcripts are easy to obtain (if we continue with the mental model of a LLM as an interviewee, this is especially evident in contrast with obtaining transripts with human users). Even for systems where the interaction is based on voice, the interaction is first translated to text using speech-to-text methods, so it can also be easily obtained. In this sense, there is no excuse for researchers not reporting full transcripts. 

One other advantage is that, while for human participants conversations often cannot be reported due to confidentiality, LLM conversations can (e.g. as of beginning of 2025, the for-profile OpenAI company allows the sharing of chat transcripts: https://openai.com/policies/sharing-publication-policy/). 


\subsubsection{Challenges}

Given that {\em chat transcripts} are easy to generate, a study might end up with a very large appendix. Consequently, online storage might be needed. Services such as Zenodo, or other long term storage for research artifacts, will likely have to be used in such situations.

Not all systems allow the reporting of interaction logs with the same ease. E.g. chat bot systems are easy to report the interactions with; OTOH, auto-complete systems, like GitHub Copilot, will be much harder to report. Indeed, the fact that CoPilot provided a recommendation during a coding session can not be replicated unless one re-creates the whole codebase state at that given point in time (and that of GitHub Copilot too). One way to report that would be sharing a screencast of the coding session. But this might be found to be too troublesome by some. 


\subsubsection{Study Types}

This guideline \should be followed for all study types. 


\subsubsection{References}

\bibliographystyle{plain}
\bibliography{../../literature.bib}

\end{document}
